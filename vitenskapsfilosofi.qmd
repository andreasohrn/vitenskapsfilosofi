---
title: "vitenskapsfilosofi"
format: pdf
bibliography: vitenskapsfilosofi.bib
csl: apa.csl
---

## Falsifikasjonisme

Falsifikasjonisme er et vitenskapelig prinsipp gjort kjent av den østeriske filosofen Karl Popper. Popper mente at innen vitenskapelig metode kan en teori kun betraktes som vitenskap hvis den er falsifiserbar. Det vil si at teorien eller hypotesen er formulert på en slik måte at man kun med bruk av deduktiv logikk og empirisk testing potensielt kan falsifisere den[@popperLogicScientificDiscovery1959]. Det er viktig å presisere at selv om et utsagn må være falsifiserbart for å regnes som vitenskap, er den ikke nødvendigvis usann. Popper mente også at en teori med flere og mer presise prediksjoner er bedre, siden den da vil være mer falsifiserbar. Eksempelvis vil en teori som sier at «alle objekter faller mot bakken med en hastighet på 9,8m/s2 i et vakuum», være bedre enn å bare si at «alle objekter faller mot bakken når de slippes i et vakuum». Det finnes altså ulike grader av falsifiserbarhet[@popperLogicScientificDiscovery1959].

Det er flere grunner til at Popper mente at falsifikasjon var den eneste riktige måten å drive ordentlig vitenskap på. Popper mente blant annet at man utelukkende må basere vitenskapen på deduktiv logikk. Bakgrunnen dette baserer seg på det David Hume beskrev som «induksjonsproblemetn». Induksjonsproblemet går kort sagt ut på at man ikke rasjonelt kan begrunne eller rettferdiggjøre induktive beslutninger, siden induktive resonnementer baserer seg på antagelsen om at noe som har skjedd før i tiden også vil skje i framtiden, også kalt uniformitetsprinsippet. Popper var opptatt av at uansett hvor mange ganger et fenomen har skjedd før, kan man aldri med 100% garanti si at det vil skje på akkurat lik måte også i framtiden. Verifisering av teorier og hypoteser må derfor basere seg på antagelser, noe som Popper trakk linjer mot pseudovitenskapen. Med bakgrunn av dette burde fokuset være på å heller forsøke å falsifisere teorier ved hjelp av deduktiv logikk og empiri. Hvis en teori står lenge uten at noen klarer å falsifisere den gjennom gjentatte forsøk, regnes den ofte som en sterkere teori, uten at man noen gang kan si at den er bekreftet.

\
Med falsifikasjonismen ønsket også Popper å svare på «demarksjonsproblemet». Altså det å skille mellom hva som er vitenskap og ikke-vitenskap. Ved å sette klare kriterier på hva som kan regnes som vitenskap, vil også vitenskapen ha høyere status. Hvis en teori eller hypotese ikke kan falsifiseres, kan man ikke lenger kalle det vitenskap, men heller konspirasjoner, myter eller ideologier. En korrekt måte å drive forskningsfelt videre på var ifølge Popper å komme opp med en hypotese ➡️ prediksjon ➡️ falsifisering ➡️ ny hypotese osv. osv. Denne vitenskapssyklusen fungerer bra hvis hypotesen er falsifiserbar og gir prediksjoner som kan testes empirisk. Popper kritiserte sterkt store åpne teorier som kunne gi svar til veldig mange ulike spørsmål. Eksempelvis kan evolusjonær psykologi kritiseres med bakgrunn i dette. Der er fokuset å forklare menneskelig atferd ved hjelp av evolusjonsteori. Problemet er det at man kun er på leting etter å bekrefte en teori eller hypotese man har, og man tolker bevisene på en måte som best mulig passer sitt eget narrativ. En slik framgangsmåte er ifølge popper intet bedre enn pseudovitenskap, og blir altfor lettvint.

\
Poppers radikale syn på hvordan man bør drive vitenskap har også blitt kritisert fra flere hold. Et aktuelt motsvar til falsifikasjon ble presentert av den franske fysikeren Pierre Duhem. Han mente at spesielt innen fysikk så kan ikke en teori i seg selv gi en prediksjon, uten hjelp av flere støttehypoteser. Bruker vi gravitasjonsloven som eksempel så sier den at alle objekter faller mot bakken med lik hastighet i et vakuum. Skal man teste dette utendørs, er det likevel veldig mange andre faktorer som spiller inn. Dette kan blant annet være luftmotstand, vind, temperatur og målefeil. Det kreves dermed støttehypoteser om hvordan disse faktorene påvirker eksperimentet for å kunne undersøke den faktiske teorien Duham mente at når eksperimenter ikke stemmer overens med prediksjoner er det flere potensielle årsaker, inkludert feil i eksperimentoppsettet, feil i forståelsen av teorien eller andre faktorer som kan spille inn. Dermed blir det nesten svært vanskelig å vite om det er støttehypotesene som er feil eller selve teorien. Dette betyr også man er avhengig av å verifisere støttehypoteser for å kunne falsifisere en teori. Problemet her er at denne verifiseringen vanligvis krever induksjon, og induksjon kan ikke rasjonelt begrunnes i følge falsifikasjonismen.

Duhams argument mot deduktiv logikk i falsifikasjonisme står enda sterkt i dag, og det virker ikke som det er mulig å unngå delvis induktiv logikk. Spørsmålet da er hvor stort problem det er at vitenskapen delvis bygger på induksjon. Det finnes flere syn på hvordan vitenskaps-metodologien bør være, og en fellesnevner er at de forsøker å sette induktive argumenter i system. Ved å undersøke hva gode induktive argumenter har til felles kan man forsøke å lage system for å optimalisere forskning og vitenskap. Ett forsøk på en slik systematisering er Baysianisme som jeg skal gå nærmere inn på i neste oppgave.

## Baysianisme

Baysiansime er en vitenskapsfilosofisk retning som baserer seg på bruken av matematisk sannsynlighetsregning og statistikk til å svare på vitenskapelige spørsmål [@godfrey-smithTheoryRealityIntroduction2003]. Et veldig sentralt konsept i bayesianismen er at troen rundt en teori eller tema skal oppdateres kontinuerlig som ny informasjon blir tilgjengelig. Hele rammeverket rundt baysiansime er basert på «Bayes Teorem», oppkalt etter statistikeren og filosofen Thomas Bayes, og kan skrives som: $$ P(A|B) = \frac{P(B|A) \times P(A)}{P(B)} $$ Bayes Teorem beskriver sjansen for at en hendelse skal skje basert på tidligere observasjoner, også kalt prior-sannsynlighet [@godfrey-smithTheoryRealityIntroduction2003]. I Bayesiansk analyse brukes denne prior-sannsynligheten til å representere oppfatningen om en hendelse før man observerer ny data. Etter ny data blir tilgjengelig, oppdateres «posterior-sannsynligheter» ved hjelp av Bayes' teorem. Slik vil man kontinuerlig regne seg fram til sannsynligheten til at noe skal forekomme. Hvis den nye informasjonen bekrefter hypotesen, vil sannsynligheten for at det forekommer igjen øke, og omvendt.

Med bakgrunn i dette vil en Baysianer svært sjeldent påstå at noe er en absolutt sannhet, men heller se på hvor sannsynlig det er å tro at noe er sant basert på matematiske utregninger. Sånn sett kan man for eksempel tenke seg til at et utfall er 60% sannsynlig i et felt hvor tidligere litteratur er ambivalent. Hvis nyere og bedre forskning på dette feltet kommer med data som støtter hypotesen, kan denne sannsynligheten økes til eks. 80% over tid. Slik leter man ikke etter verifisering eller falsifisering av hypoteser, men heller oppdaterer kunnskapen sin gradvis over tid.

Denne holistiske tilnærming til vitenskapen blir ofte sett på som en styrke med Baysianismen sammenlignet med blant annet HD-metoden. HD-metoden baserer seg i større grad på en binær tilnærming til hypoteser. Enten er en hypotese verifisert, eller så er den falsifisert. Ved en slik metode kan det være vanskelig å reflektere usikkerheter i forskningsfelt. I tillegg vil en slik metode i større grad slite med å ta hensyn til en gradvis endring innenfor feltet.

Selv om rammeverket rundt Baysianismen kan gi et godt og realistisk bilde på ulike forskningsspørsmål er det også noen svakheter. Ett problem som kan dukke opp er hvor man skal få all de tidligere sannsynlighetene fra. Forskningsfelt eller tema som er forsket lite på fra før er særlig sårbare. I disse situasjonene kan data fra studier med lav kvalitet eller mangler påvirke posterior-resultate i for stor grad. Man kan tenke seg til at dette vil jevnes ut når man får mer data og informasjon på feltet, men også da må man være obs på eventuelle bias. På svært store forskningsfelt kan det også være en stor utfordring å få oversikt over og strukturere en representasjon av prior sannsynlighet. I tillegg til dette er det ingen veldefinert metode å definere prior sannsynlighet. Dette kan medføre at forskjellige personer kan bruke ulike prior sannsynligheter for de samme eksperimentene [@k.hackenbergerBayesNotBayes2019]. Hvor store konsekvenser dette medfører er det vanskelig og si, og det kommer nok helt an på situasjonen. På en side kan det være interessant å utforske samme eksperiment med ulike prior sannsynligheter, for å få et større overblikk. På den andre siden er det sårbart mot at personer kan velge å benytte seg av prior som er fordelaktig for dem. \newpage
